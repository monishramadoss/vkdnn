
#version 460
#extension GL_EXT_shader_explicit_arithmetic_types_float32 : enable 
#define NUM_THREADS 128
#define WARPSIZE 32
#define BN NUM_THREADS
#define BM 64
#define BK 16
#define WN 64
#define WM 32
#define TN 4
#define TM 4
#define WNINTER 1
#define WMINTER 4
#define WSUBN 64
#define WSUBM 0
#define NUM_WARPS 4

layout(local_size_x = NUM_THREADS) in;
layout(push_constant) uniform pushBlock {
    uint m;
    uint k;
    uint n;
    float alpha;
    float beta;
};

layout(binding=0) buffer buf_0 { float tensor_0[]; };
layout(binding=1) buffer buf_1 { float tensor_1[]; };
layout(binding=2) buffer buf_2 { float tensor_2[]; };


float regM[WMINTER * TM];
float regN[WNINTER * TN];
float threadResults[WMINTER * TM * WNINTER * TN];

shared float As[BM * BK];
shared float Bs[BK * BN];



    
void loadRegs(uint rowStrideA, uint rowStrideB, uint a, uint b, uint as, uint bs, uint innerRowA, uint innerColA, uint innerRowB, uint innerColB){
    //loads stuff
    for(uint offset = 0; offset+rowStrideA <= BM; offset += rowStrideA) {
        uint xIdx = a + (innerRowA + offset) * k + innerColA * 4;
        vec4 tmp = vec4(tensor_0[xIdx + 0], tensor_0[xIdx + 1], tensor_0[xIdx + 2], tensor_0[xIdx + 3]);
        As[as + ((innerColA * 4) + 0) * BM + innerRowA + offset] = tmp.x;
        As[as + ((innerColA * 4) + 1) * BM + innerRowA + offset] = tmp.y;
        As[as + ((innerColA * 4) + 2) * BM + innerRowA + offset] = tmp.z;
        As[as + ((innerColA * 4) + 3) * BM + innerRowA + offset] = tmp.w;
    }

    for(uint offset = 0; offset+rowStrideB <= BK; offset += rowStrideB) {
        uint mIdx = b + (innerRowB + offset) * n + innerColB * 4;
        vec4 tmp = vec4(tensor_1[mIdx + 0], tensor_1[mIdx + 1], tensor_1[mIdx + 2], tensor_1[mIdx + 3]);
        Bs[bs + (innerRowB + offset) * BN + innerColB * 4 + 0] = tmp.x;
        Bs[bs + (innerRowB + offset) * BN + innerColB * 4 + 1] = tmp.y;
        Bs[bs + (innerRowB + offset) * BN + innerColB * 4 + 2] = tmp.z;
        Bs[bs + (innerRowB + offset) * BN + innerColB * 4 + 3] = tmp.w;
    }
}

void processFromSmem(uint as, uint bs uint warpRow, uint warpCol, uint threadRowWarp, uint threadColWarp){
    for(uint dotIdx = 0; dotIdx < BK; ++dotIdx){
        for(uint wSubRowIdx = 0; wSubRowIdx < WMINTER; ++wSubRowIdx){
            for(uint i = 0; i < TM; ++i)
                regM[wSubRowIdx * TM + i] = As[as + (dotIdx * BM) + (warpRow * WM) + (wSubRowIdx * WSUBM) + (threadRowWarp * TM) + i];
        }

        for(uint wSubColIdx = 0; wSubColIdx < WNINTER; ++wSubColIdx){
            for(uint i = 0; i < TN; ++i)
                regN[wSubColIdx * TN + i] = Bs[bs + (dotIdx * BN) + (warpCol * WN) + (wSubColIdx * WSUBN) + (threadColWarp * TN) + i];
        }

        for(uint wSubRowIdx = 0; wSubRowIdx < WMINTER; ++wSubRowIdx){
            for(uint wSubColIdx = 0; wSubColIdx < WNINTER; ++wSubColIdx){

                for (uint resIdxM = 0; resIdxM < TM; ++resIdxM) {
                    for (uint resIdxN = 0; resIdxN < TN; ++resIdxN) {

                        uint reg_idx = (wSubRowIdx * TM + resIdxM) * (WNINTER * TN) + (wSubColIdx * TN) + resIdxN;
                        threadResults[reg_idx] = fma(regM[wSubRowIdx * TM + resIdxM], regN[wSubColIdx * TN + resIdxN], threadResults[reg_idx]);
                    }
                }
            }
        }
    }
}

void main() {
    uint cRow = gl_WorkGroupID.y;
    uint cCol = gl_WorkGroupID.x;

    uint tid = gl_LocalInvocationID.x;

    uint warpIdx = tid / WARPSIZE;
    uint warpCol = warpIdx % (BN / WN);
    uint warpRow = warpIdx / (BN / WN);

    uint threadIdxWarp = tid % WARPSIZE;
    uint threadColWarp = threadIdxWarp % (WSUBN / TN);
    uint threadRowWarp = threadIdxWarp / (WSUBN / TN);

    uint a = cRow * BM * k;
    uint b = cCol * BN;
    uint c = ((cRow * BM) + (warpRow * WM)) * n + (cCol * BN) + (warpCol * WN);
    

    uint innerRowA = tid / (BK / 4);
    uint innerColA = tid % (BK / 4);
    uint rowStrideA = (NUM_THREADS * 4) / BK;
    
    uint innerRowB = tid / (BN / 4);
    uint innerColB = tid % (BN / 4);
    uint rowStrideB = NUM_THREADS / (BN / 4);


    for(uint blkIdx = 0; blkIdx < k; blkIdx += BK) {
        loadRegs(rowStrideA, rowStrideB, a, b, 0, 0, innerRowA, innerColA, innerRowB, innerColB);
        //memoryBarrierShared();
        barrier();
        processFromSmem(0, 0, warpRow, warpCol, threadRowWarp, threadColWarp);

        a += BK;
        b += BK * n;
       
        barrier();
    }

    for(uint wSubRowIdx = 0; wSubRowIdx < WMINTER; ++wSubRowIdx) {
        for(uint wSubColIdx = 0; wSubColIdx < WNINTER; ++wSubColIdx) {
            uint c_interm = c + (wSubRowIdx * WSUBM) * n + wSubColIdx * WSUBN;

            for(uint resIdxM = 0; resIdxM < TM; ++resIdxM) {
                for(uint resIdxN = 0; resIdxN < TN; resIdxN += 4) {

                    uint c_idx = c_interm + (threadRowWarp * TM + resIdxM) * n + threadColWarp * TN + resIdxN;
                    vec4 tmp = vec4(tensor_2[c_idx + 0], tensor_2[c_idx + 1], tensor_2[c_idx + 2], tensor_2[c_idx + 3]);
                    uint i = (wSubRowIdx * TM + resIdxM) * (WNINTER * TN) + wSubColIdx * TN + resIdxN;
                    
                    tmp.x = fma(alpha, threadResults[i + 0], beta * tmp.x);
                    tmp.y = fma(alpha, threadResults[i + 1], beta * tmp.y);
                    tmp.z = fma(alpha, threadResults[i + 2], beta * tmp.z);
                    tmp.w = fma(alpha, threadResults[i + 3], beta * tmp.w);
                    
                    tensor_2[c_idx + 0] = tmp.x;
                    tensor_2[c_idx + 1] = tmp.y;
                    tensor_2[c_idx + 2] = tmp.z;
                    tensor_2[c_idx + 3] = tmp.w;                    
                }
            }
        }
    }
   
}